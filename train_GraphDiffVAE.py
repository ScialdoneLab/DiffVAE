"""
Code Author: Ioana Bica (ioana.bica95@gmail.com), Marco Stock (marco.stock@tum.de)
"""

import os
import argparse
import numpy as np
import pandas as pd
import tensorflow as tf

from autoencoder_models.GraphDiffVAE import GraphDiffVAE
from data.data_processing import get_gene_expression_data
from data.data_processing import scale_gene_expression_df
from data.build_graphs import build_correlation_graph

from GRN_functions import *

import time

def init_arg():
    parser = argparse.ArgumentParser()
    parser.add_argument("--gene_expression_filename", default='data/Zebrafish/GE_mvg.csv')
    parser.add_argument("--hidden_dimensions", default=[512], nargs="*", type=int)
    parser.add_argument("--latent_dimension", default=50, type=int)
    parser.add_argument("--epochs", default=200, type=int)
    parser.add_argument("--learning_rate", default=0.0001, type=float)
    parser.add_argument("--model_name", default='graph_test')
    parser.add_argument("--input_adj_matrix")
    parser.add_argument("--initial_node_features")
    parser.add_argument("--loss", default="categorical") #categorical, binary or f1
    parser.add_argument("--model", default="best") #best or last model
    parser.add_argument("--kl_weight", default=1, type=float) #weight of KL loss in total sum
    parser.add_argument("--val_ratio", default=0.7, type=float) #ratio of edges used for training + validation
    parser.add_argument("--symmetric", dest='symmetric', action='store_true', default=False) #construct symmetric adjacency matrix
    parser.add_argument("--train_ratio", default=0.4, type=float) #ratio of edges used for training
    parser.add_argument("--train_ratio_example", default=0.4, type=float) #ratio of edges used for each training example
    parser.add_argument("--examples", default=1, type=int) #amount of examples generated by subgraph sampling used for training
    parser.add_argument("--diag", default=None, type=int) #0 or 1 along the input adjacency diagonal
    parser.add_argument("--rm_iso_nodes", dest='rm_iso_nodes', action='store_true', default=False) #if isolated nodes in input graph should be removed
    

    return parser.parse_args()

if __name__ == '__main__':

    args = init_arg()
    if not os.path.exists('results/Graphs'):
        os.mkdir('results/Graphs')
    if not os.path.exists('results/Models'):
        os.mkdir('results/Models')

    model_timestamp = time.strftime("%Y%m%d_%H%M%S")
    tf.compat.v1.disable_eager_execution()
    print(tf.executing_eagerly())

    if args.input_adj_matrix is None:
        gene_expression_normalized = get_gene_expression_data(args.gene_expression_filename)
        adj_matrix, initial_node_features = build_correlation_graph(gene_expression_normalized, num_neighbors=2)
    else:
        adj_matrix = np.genfromtxt(args.input_adj_matrix, delimiter=';', dtype='float64')
        initial_node_features_raw =  np.genfromtxt(args.initial_node_features, delimiter=';', dtype='float64')
        if args.rm_iso_nodes:
            adj_matrix, initial_node_features_raw = crop_isolated_nodes(adj_matrix, initial_node_features_raw)
        initial_node_features = scale_gene_expression_df(initial_node_features_raw)

    #np.savetxt('results/Graphs/' + model_timestamp + '_input_adj_matrix_' + args.model_name + '.csv', adj_matrix, delimiter=";")
    #np.savetxt('results/Graphs/' + model_timestamp + '_input_node_feat_' + args.model_name + '.csv', initial_node_features, delimiter=";")

    adj_matrix = preprocess_input_adj(adj_matrix, args.symmetric, args.diag)
    adj_val = gen_subgraph(adj_matrix, args.val_ratio, args.symmetric)

    adj_train,adj_train_total = gen_training_array(adj_val, args.train_ratio, args.train_ratio_example, args.symmetric, args.examples)
    np.savetxt('results/Graphs/' + model_timestamp + '_training_subgraph_' + args.model_name + '.csv', adj_train_total, delimiter=";")
    np.savetxt('results/Graphs/' + model_timestamp + '_validation_subgraph_' + args.model_name + '.csv', adj_val, delimiter=";")
    print("Dimensions of initial_node_features: " + str(initial_node_features.shape[0]) + ":"+ str(initial_node_features.shape[1]))
    print("Dimensions of adj_matrix: " + str(adj_matrix.shape[0]) + ":"+ str(adj_matrix.shape[1]))
    print("Sum of original graph edges: " + str(adj_matrix.sum()))
    print("Sum of validation graph edges: " + str(adj_val.sum()))
    print("Sum of total training graph edges: " + str(adj_train_total.sum()))
    print("Sum of single training graph edges: " + str(adj_train.sum()))
    
    GraphVAE_model=GraphDiffVAE(num_nodes=adj_matrix.shape[0], num_features=initial_node_features.shape[1],
                                adj_matrix=adj_train, latent_dim=args.latent_dimension,
                                hidden_layers_dim=args.hidden_dimensions,
                                epochs=args.epochs,
                                learning_rate=args.learning_rate,
                                loss_mode=args.loss,
                                model_select=args.model,
                                kl_weight=args.kl_weight,
                                timestamp=model_timestamp,
                                adj_val=adj_val)

    predictions, latent_res = GraphVAE_model.train_vae(initial_node_features)
    np.savetxt('results/Graphs/' + model_timestamp + '_pred_adj_' + args.model_name + '_hidden_' + "_".join(str(n) for n in args.hidden_dimensions) + '_latent_' + str(args.latent_dimension) + '_' + args.loss +'.csv', predictions, delimiter=";")
    #np.savetxt('results/Graphs/' + model_timestamp + '_node_latent_' + args.model_name + '.csv', latent_res, delimiter=";")

    print("ROC AUC test set: " + str(test_auc(adj_matrix, adj_val, predictions)))
    print(test_classification_report(adj_matrix, adj_val, predictions))
    
